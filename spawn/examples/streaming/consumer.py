#!/usr/bin/env python3
"""
Example streaming data consumer for Spawn pipelines.

This consumer receives processed data from upstream processors
and writes it to a local file. The file will be uploaded to S3
by the Spawn pipeline framework.
"""

import argparse
import json
import socket
import struct
import time


def load_peer_discovery():
    """Load the peer discovery file generated by Spawn."""
    with open('/etc/spawn/pipeline-peers.json', 'r') as f:
        return json.load(f)


def recv_chunk(sock: socket.socket) -> bytes:
    """Receive a length-prefixed chunk from TCP."""
    # Read 4-byte length prefix
    length_data = recv_exactly(sock, 4)
    if not length_data:
        return None

    length = struct.unpack('>I', length_data)[0]

    # Sanity check
    if length > 100 * 1024 * 1024:  # 100MB max
        raise ValueError(f"Chunk too large: {length} bytes")

    # Read data
    return recv_exactly(sock, length)


def recv_exactly(sock: socket.socket, n: int) -> bytes:
    """Receive exactly n bytes from socket."""
    data = b''
    while len(data) < n:
        chunk = sock.recv(n - len(data))
        if not chunk:
            return None
        data += chunk
    return data


def main():
    parser = argparse.ArgumentParser(description='Stream data consumer')
    parser.add_argument('--output', type=str, default='/data/results.csv',
                       help='Output file path')
    args = parser.parse_args()

    # Load peer discovery
    peers = load_peer_discovery()

    # Get upstream processor info
    upstream_stages = peers.get('upstream_stages', {})
    if not upstream_stages:
        print("Error: No upstream stages found")
        return 1

    # Get all upstream instances (could be multiple processors)
    upstream_instances = []
    for stage_id, instances in upstream_stages.items():
        upstream_instances.extend(instances)

    if not upstream_instances:
        print("Error: No upstream instances found")
        return 1

    print(f"Consumer configuration:")
    print(f"  Upstream processors: {len(upstream_instances)}")
    print(f"  Output file: {args.output}")

    # For this example, connect to the first processor
    # In a real fan-in scenario, you'd connect to all and merge
    upstream = upstream_instances[0]
    upstream_ip = upstream['private_ip']
    upstream_port = 50001  # Processor listens on 50001

    print(f"Connecting to processor at {upstream_ip}:{upstream_port}")

    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    sock.connect((upstream_ip, upstream_port))
    print("Connected to processor")

    # Open output file
    with open(args.output, 'w') as f:
        # Write CSV header
        f.write("record_id,value,timestamp\n")

        batch_count = 0
        total_records = 0
        start_time = time.time()

        while True:
            try:
                # Receive batch
                chunk = recv_chunk(sock)
                if not chunk:
                    print("Upstream connection closed")
                    break

                # Write batch to file
                lines = chunk.decode('utf-8').strip().split('\n')
                for line in lines:
                    if line:
                        f.write(line + '\n')
                        total_records += 1

                batch_count += 1

                if batch_count % 10 == 0:
                    elapsed = time.time() - start_time
                    rate = total_records / elapsed
                    print(f"Received {batch_count} batches, "
                          f"{total_records} records "
                          f"({rate:.0f} records/sec)")

            except Exception as e:
                print(f"Error receiving data: {e}")
                break

    sock.close()

    elapsed = time.time() - start_time
    print(f"\nConsumer finished:")
    print(f"  Total batches: {batch_count}")
    print(f"  Total records: {total_records}")
    print(f"  Duration: {elapsed:.1f}s")
    print(f"  Rate: {total_records/elapsed:.0f} records/sec")
    print(f"  Output: {args.output}")

    return 0


if __name__ == '__main__':
    exit(main())
