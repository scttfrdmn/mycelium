#!/usr/bin/env python3
"""
Example streaming data producer for Spawn pipelines.

This producer generates synthetic data and streams it to downstream
consumers via TCP. It demonstrates how to use the peer discovery
file to find downstream stages.
"""

import argparse
import json
import os
import socket
import struct
import time
from typing import List


def load_peer_discovery():
    """Load the peer discovery file generated by Spawn."""
    with open('/etc/spawn/pipeline-peers.json', 'r') as f:
        return json.load(f)


def send_chunk(sock: socket.socket, data: bytes) -> None:
    """Send a length-prefixed chunk over TCP."""
    length = len(data)
    # Send 4-byte length prefix (big-endian)
    sock.sendall(struct.pack('>I', length))
    # Send data
    sock.sendall(data)


def generate_batch(batch_id: int, batch_size: int) -> bytes:
    """Generate a batch of synthetic data."""
    lines = []
    for i in range(batch_size):
        record_id = batch_id * batch_size + i
        value = record_id * 1.5  # Some computation
        lines.append(f"{record_id},{value},{time.time()}")

    return '\n'.join(lines).encode('utf-8')


def main():
    parser = argparse.ArgumentParser(description='Stream data producer')
    parser.add_argument('--port', type=int, default=50000, help='Listen port')
    parser.add_argument('--batch-size', type=int,
                       default=int(os.getenv('BATCH_SIZE', '1000')),
                       help='Records per batch')
    parser.add_argument('--total-batches', type=int,
                       default=int(os.getenv('TOTAL_BATCHES', '100')),
                       help='Total batches to send')
    args = parser.parse_args()

    # Create TCP server
    server_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    server_sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    server_sock.bind(('0.0.0.0', args.port))
    server_sock.listen(5)

    print(f"Producer listening on port {args.port}")
    print(f"Waiting for {args.total_batches} connections from downstream stages...")

    # Load peer discovery to see how many consumers we expect
    try:
        peers = load_peer_discovery()
        downstream_stages = peers.get('downstream_stages', {})
        total_consumers = sum(len(instances)
                            for instances in downstream_stages.values())
        print(f"Expecting {total_consumers} downstream consumers")
    except Exception as e:
        print(f"Warning: Could not load peer discovery: {e}")
        total_consumers = 1

    # Accept connections from all downstream consumers
    connections = []
    for i in range(total_consumers):
        conn, addr = server_sock.accept()
        print(f"Accepted connection {i+1}/{total_consumers} from {addr}")
        connections.append(conn)

    print(f"All consumers connected. Streaming {args.total_batches} batches...")

    # Stream data to all consumers
    start_time = time.time()
    for batch_id in range(args.total_batches):
        # Generate batch
        batch_data = generate_batch(batch_id, args.batch_size)

        # Send to all consumers
        for conn in connections:
            try:
                send_chunk(conn, batch_data)
            except Exception as e:
                print(f"Error sending to consumer: {e}")

        if (batch_id + 1) % 10 == 0:
            elapsed = time.time() - start_time
            rate = (batch_id + 1) * args.batch_size / elapsed
            print(f"Sent batch {batch_id + 1}/{args.total_batches} "
                  f"({rate:.0f} records/sec)")

    # Close connections
    print("Streaming complete. Closing connections...")
    for conn in connections:
        conn.close()
    server_sock.close()

    elapsed = time.time() - start_time
    total_records = args.total_batches * args.batch_size
    print(f"Sent {total_records} records in {elapsed:.1f}s "
          f"({total_records/elapsed:.0f} records/sec)")


if __name__ == '__main__':
    main()
